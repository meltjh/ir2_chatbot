{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"drive_test_2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"mAvasfrILtby","colab_type":"code","outputId":"71ec5c93-6c1a-4439-a7ef-617ff85479ed","executionInfo":{"status":"ok","timestamp":1544972195493,"user_tz":-60,"elapsed":128547,"user":{"displayName":"Richard Olij","photoUrl":"https://lh6.googleusercontent.com/-SDhgkQ9WYYg/AAAAAAAAAAI/AAAAAAAAAD0/TxoCNCLTjP0/s64/photo.jpg","userId":"02869672473237543558"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"cell_type":"code","source":["# Install a Drive FUSE wrapper.\n","# https://github.com/astrada/google-drive-ocamlfuse\n","# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","# Generate auth tokens for Colab\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","# Generate creds for the Drive FUSE library.\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","\n","\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","# Create a directory and mount Google Drive using that directory.\n","!mkdir -p Drive\n","!google-drive-ocamlfuse Drive\n","\n","# Install stuff\n","!pip3 install torch torchvision\n","!pip3 install nltk\n","import nltk\n","nltk.download('punkt')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["··········\n","fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"NwhYdNm4OPAE","colab_type":"code","outputId":"4fabc9f8-1340-4fe2-cc47-515fc0f21e59","executionInfo":{"status":"ok","timestamp":1544970210658,"user_tz":-60,"elapsed":3703,"user":{"displayName":"Richard Olij","photoUrl":"https://lh6.googleusercontent.com/-SDhgkQ9WYYg/AAAAAAAAAAI/AAAAAAAAAD0/TxoCNCLTjP0/s64/photo.jpg","userId":"02869672473237543558"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["!cd Drive/IR2_project_drive_new/ir2_chatbot/checkpoints/FirstTry_500_True && ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cp-1.txt  cp-2.txt  cp-3.txt\n"],"name":"stdout"}]},{"metadata":{"id":"t5q0UShTL_cp","colab_type":"code","outputId":"bef8756e-b8c6-4bbe-bc8b-73b62c3de6bb","executionInfo":{"status":"ok","timestamp":1544968379140,"user_tz":-60,"elapsed":1125147,"user":{"displayName":"Richard Olij","photoUrl":"https://lh6.googleusercontent.com/-SDhgkQ9WYYg/AAAAAAAAAAI/AAAAAAAAAD0/TxoCNCLTjP0/s64/photo.jpg","userId":"02869672473237543558"}},"colab":{"base_uri":"https://localhost:8080/","height":717}},"cell_type":"code","source":["!cd Drive/IR2_project_drive_new/ir2_chatbot && python3 train.py --exp_id_prefix \"FirstTry\" --n_epochs 3 --batch_size 256 --hidden_dim 128 --emb_dim 50 --merge_type oracle --min_occ 500 --use_bilin True"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Bilinear: True, Merge type: oracle, epochs: 3, batch size: 256, hidden dim: 128, embedding dim: 50, min occurences: 500.\n","Getting glove vocab\n","==== Getting the datasets ====\n","\n","Processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 17.11 seconds\n","\n","Adding words to the word2id\n","Start getting the words that occur more than 500 times\n","Size of the training dataset: 14168 words\n","Size of GLoVE: 400000 words\n","Without a threshold, the number of words in the intersection is: 13490\n","-- Finished getting the 215 words that occur more than 500 times\n","It took 0.04 seconds\n","\n","Getting the training set\n","\n","Finished adding words to the word2id\n","It took 1.13 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","\n","Processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 19.04 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","\n","==== Finished getting the datasets ====\n","\n","Constructing embeddings matrix\n","Training: Epoch 001/003 Example 04352/04352 (01:58/00:06) | Bilinear loss: 0.1765, Decoder loss: 3.8631\n","Evaluating: Epoch 001/003 Example 04608/04608 (03:40/00:12) | Bilinear loss: 0.1775, Decoder loss: 3.3233\n","Training: Epoch 002/003 Example 04352/04352 (01:59/00:07) | Bilinear loss: 0.1711, Decoder loss: 3.2162\n","Evaluating: Epoch 002/003 Example 04608/04608 (03:39/00:12) | Bilinear loss: 0.1718, Decoder loss: 3.1286\n","Training: Epoch 003/003 Example 04352/04352 (02:01/00:07) | Bilinear loss: 0.1789, Decoder loss: 3.0344\n","Evaluating: Epoch 003/003 Example 04608/04608 (03:39/00:12) | Bilinear loss: 0.1766, Decoder loss: 2.9825\n"],"name":"stdout"}]},{"metadata":{"id":"epnQ_N8HSt46","colab_type":"code","outputId":"8cb70fd0-419a-4acd-9d97-e426a626bac9","colab":{"base_uri":"https://localhost:8080/","height":661}},"cell_type":"code","source":["!cd Drive/IR2_project_drive_new/ir2_chatbot && python3 train.py --exp_id_prefix \"FirstTry\" --n_epochs 4 --batch_size 256 --hidden_dim 128 --emb_dim 50 --merge_type oracle --min_occ 500 --use_bilin True"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Bilinear: True, Merge type: oracle, epochs: 4, batch size: 256, hidden dim: 128, embedding dim: 50, min occurences: 500.\n","Getting glove vocab\n","==== Getting the datasets ====\n","\n","Processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 20.64 seconds\n","\n","Adding words to the word2id\n","Start getting the words that occur more than 500 times\n","Size of the training dataset: 14168 words\n","Size of GLoVE: 400000 words\n","Without a threshold, the number of words in the intersection is: 13490\n","-- Finished getting the 215 words that occur more than 500 times\n","It took 0.05 seconds\n","\n","Getting the training set\n","\n","Finished adding words to the word2id\n","It took 1.25 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","\n","Processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 21.40 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","\n","==== Finished getting the datasets ====\n","\n","Constructing embeddings matrix\n","checkpoints ['checkpoints/FirstTry_500_True/cp-2.txt', 'checkpoints/FirstTry_500_True/cp-3.txt', 'checkpoints/FirstTry_500_True/cp-1.txt']\n","Training: Epoch 004/004 Example 03328/04352 (01:37/00:37) | Bilinear loss: 0.1721, Decoder loss: 3.7898"],"name":"stdout"}]},{"metadata":{"id":"rUCc3C-ZYWen","colab_type":"code","outputId":"e32b12f3-b83f-48fe-8144-be703e581a48","executionInfo":{"status":"ok","timestamp":1544971387408,"user_tz":-60,"elapsed":359,"user":{"displayName":"Richard Olij","photoUrl":"https://lh6.googleusercontent.com/-SDhgkQ9WYYg/AAAAAAAAAAI/AAAAAAAAAD0/TxoCNCLTjP0/s64/photo.jpg","userId":"02869672473237543558"}},"colab":{"base_uri":"https://localhost:8080/","height":666}},"cell_type":"code","source":["!cd Drive/IR2_project_drive_new/ir2_chatbot && python3 train.py --exp_id_prefix \"FirstTry\" --n_epochs 4 --batch_size 256 --hidden_dim 128 --emb_dim 50 --merge_type oracle --min_occ 500 --use_bilin True"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Bilinear: True, Merge type: oracle, epochs: 4, batch size: 256, hidden dim: 128, embedding dim: 50, min occurences: 500.\n","Getting glove vocab\n","==== Getting the datasets ====\n","\n","Processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 28.82 seconds\n","\n","Adding words to the word2id\n","Start getting the words that occur more than 500 times\n","Size of the training dataset: 14168 words\n","Size of GLoVE: 400000 words\n","Without a threshold, the number of words in the intersection is: 13490\n","-- Finished getting the 215 words that occur more than 500 times\n","It took 0.08 seconds\n","\n","Getting the training set\n","\n","Finished adding words to the word2id\n","It took 1.77 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","\n","Processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 30.35 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","\n","==== Finished getting the datasets ====\n","\n","Constructing embeddings matrix\n","checkpoints ['checkpoints/FirstTry_500_True/cp-3.txt', 'checkpoints/FirstTry_500_True/cp-2.txt', 'checkpoints/FirstTry_500_True/cp-1.txt']\n","Training: Epoch 004/004 Example 04352/04352 (02:50/00:10) | Bilinear loss: 0.1714, Decoder loss: 3.6535\n","Evaluating: Epoch 004/004 Example 04608/04608 (06:23/00:21) | Bilinear loss: 0.1697, Decoder loss: 3.2009\n"],"name":"stdout"}]},{"metadata":{"id":"EPDJLH_AgvK9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":666},"outputId":"3a3e7f37-4ba8-4505-850c-3233869e0b89","executionInfo":{"status":"ok","timestamp":1544972822533,"user_tz":-60,"elapsed":738157,"user":{"displayName":"Richard Olij","photoUrl":"https://lh6.googleusercontent.com/-SDhgkQ9WYYg/AAAAAAAAAAI/AAAAAAAAAD0/TxoCNCLTjP0/s64/photo.jpg","userId":"02869672473237543558"}}},"cell_type":"code","source":["!cd Drive/IR2_project_drive_new/ir2_chatbot && python3 train.py --exp_id_prefix \"FirstTry\" --n_epochs 5 --batch_size 256 --hidden_dim 128 --emb_dim 50 --merge_type oracle --min_occ 500 --use_bilin True"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Bilinear: True, Merge type: oracle, epochs: 5, batch size: 256, hidden dim: 128, embedding dim: 50, min occurences: 500.\n","Getting glove vocab\n","==== Getting the datasets ====\n","\n","Processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 23.11 seconds\n","\n","Adding words to the word2id\n","Start getting the words that occur more than 500 times\n","Size of the training dataset: 14168 words\n","Size of GLoVE: 400000 words\n","Without a threshold, the number of words in the intersection is: 13490\n","-- Finished getting the 215 words that occur more than 500 times\n","It took 0.05 seconds\n","\n","Getting the training set\n","\n","Finished adding words to the word2id\n","It took 1.31 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","\n","Processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 20.42 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","\n","==== Finished getting the datasets ====\n","\n","Constructing embeddings matrix\n","checkpoints ['checkpoints/FirstTry_500_True/cp-1.txt', 'checkpoints/FirstTry_500_True/cp-2.txt', 'checkpoints/FirstTry_500_True/cp-3.txt', 'checkpoints/FirstTry_500_True/cp-4.txt']\n","Training: Epoch 005/005 Example 04352/04352 (02:07/00:07) | Bilinear loss: 0.1698, Decoder loss: 3.6792\n","Evaluating: Epoch 005/005 Example 04608/04608 (06:34/00:21) | Bilinear loss: 0.1683, Decoder loss: 3.2054\n"],"name":"stdout"}]},{"metadata":{"id":"Bs6myNWQmLvH","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"Vxx80t5JmL3B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":768},"outputId":"29509c61-25e9-4b0d-d728-623bbc531c9a","executionInfo":{"status":"ok","timestamp":1544973656215,"user_tz":-60,"elapsed":77079,"user":{"displayName":"Richard Olij","photoUrl":"https://lh6.googleusercontent.com/-SDhgkQ9WYYg/AAAAAAAAAAI/AAAAAAAAAD0/TxoCNCLTjP0/s64/photo.jpg","userId":"02869672473237543558"}}},"cell_type":"code","source":["!cd Drive/IR2_project_drive_new/ir2_chatbot && python3 train.py --exp_id_prefix \"e25_b128_h128_em100_orc_9_True\" --n_epochs 25 --batch_size 128 --hidden_dim 128 --emb_dim 100 --merge_type oracle --min_occ 9 --use_bilin True"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Bilinear: True, Merge type: oracle, epochs: 25, batch size: 128, hidden dim: 128, embedding dim: 100, min occurences: 9.\n","Getting glove vocab\n","==== Getting the datasets ====\n","\n","Processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","Reading the file\n","Traceback (most recent call last):\n","  File \"/content/Drive/IR2_project_drive_new/ir2_chatbot/read_data.py\", line 41, in read\n","    resources = list(map(word_tokenize, nltk.sent_tokenize(context)))\n","  File \"/content/Drive/IR2_project_drive_new/ir2_chatbot/read_data.py\", line 193, in word_tokenize\n","    return [token.replace(\"''\", '\"').replace(\"``\", '\"') for token in nltk.word_tokenize(tokens)]\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\", line 128, in word_tokenize\n","    sentences = [text] if preserve_line else sent_tokenize(text, language)\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/__init__.py\", line 95, in sent_tokenize\n","    return tokenizer.tokenize(text)\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\", line 1237, in tokenize\n","    return list(self.sentences_from_text(text, realign_boundaries))\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\", line 1285, in sentences_from_text\n","    return [text[s:e] for s, e in self.span_tokenize(text, realign_boundaries)]\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\", line 1276, in span_tokenize\n","    return [(sl.start, sl.stop) for sl in slices]\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\", line 1276, in <listcomp>\n","    return [(sl.start, sl.stop) for sl in slices]\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\", line 1316, in _realign_boundaries\n","    for sl1, sl2 in _pair_iter(slices):\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\", line 312, in _pair_iter\n","    prev = next(it)\n","  File \"/usr/local/lib/python3.6/dist-packages/nltk/tokenize/punkt.py\", line 1289, in _slices_from_text\n","    for match in self._lang_vars.period_context_re().finditer(text):\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"train.py\", line 113, in <module>\n","    train_data, val_data, _, word2id = get_datasets(\"data/experiment_data/bidaf/{}_short/\".format(P.MERGE_TYPE), P.BATCH_SIZE, P.MIN_OCCURENCE, glove_vocab, False)\n","  File \"/content/Drive/IR2_project_drive_new/ir2_chatbot/read_data.py\", line 174, in get_datasets\n","    train_data = get_single_dataset(path + \"test-v1.1.json\", word2id, batch_size, True, min_occurence, glove_vocab, print_freqs)\n","  File \"/content/Drive/IR2_project_drive_new/ir2_chatbot/read_data.py\", line 156, in get_single_dataset\n","    data = read(filename, word2id, is_train, min_occurence, glove_vocab)\n","  File \"/content/Drive/IR2_project_drive_new/ir2_chatbot/read_data.py\", line 58, in read\n","    \"answer_start\": answer_start, \"resources\": resources2id})\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"metadata":{"id":"4kY5EoxZmL-B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"outputId":"ee7d436e-0086-4762-8fd7-64194ec059c1"},"cell_type":"code","source":["!cd Drive/IR2_project_drive_new/ir2_chatbot && python3 train.py --exp_id_prefix \"e25_b128_h128_em100_orc_9_False\" --n_epochs 25 --batch_size 128 --hidden_dim 128 --emb_dim 100 --merge_type oracle --min_occ 9 --use_bilin False"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Bilinear: True, Merge type: oracle, epochs: 25, batch size: 128, hidden dim: 128, embedding dim: 100, min occurences: 9.\n","Getting glove vocab\n"],"name":"stdout"}]},{"metadata":{"id":"wmd4iVUX81oP","colab_type":"code","colab":{}},"cell_type":"code","source":["# !cd Drive/IR2_project_drive_new/ir2_chatbot && python3 train.py --help"],"execution_count":0,"outputs":[]}]}