{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"drive_test_1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"mAvasfrILtby","colab_type":"code","outputId":"8a9e5d5c-d8cf-41d7-900c-b9d27b66641a","executionInfo":{"status":"ok","timestamp":1545135963842,"user_tz":-60,"elapsed":35041,"user":{"displayName":"Richard Olij","photoUrl":"https://lh6.googleusercontent.com/-SDhgkQ9WYYg/AAAAAAAAAAI/AAAAAAAAAD0/TxoCNCLTjP0/s64/photo.jpg","userId":"02869672473237543558"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"cell_type":"code","source":["# Install a Drive FUSE wrapper.\n","# https://github.com/astrada/google-drive-ocamlfuse\n","# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","# Generate auth tokens for Colab\n","from google.colab import auth\n","auth.authenticate_user()\n","\n","# Generate creds for the Drive FUSE library.\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","\n","\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","# Create a directory and mount Google Drive using that directory.\n","!mkdir -p Drive\n","!google-drive-ocamlfuse Drive\n","\n","# Install stuff\n","!pip3 install torch torchvision\n","!pip3 install nltk\n","import nltk\n","nltk.download('punkt')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["··········\n","fuse: mountpoint is not empty\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"-zH6jLqwBb5T","colab_type":"code","outputId":"9f115550-d52d-44f3-e25e-0895187c431e","colab":{"base_uri":"https://localhost:8080/","height":1615},"executionInfo":{"status":"ok","timestamp":1545153795212,"user_tz":-60,"elapsed":4931,"user":{"displayName":"Richard Olij","photoUrl":"https://lh6.googleusercontent.com/-SDhgkQ9WYYg/AAAAAAAAAAI/AAAAAAAAAD0/TxoCNCLTjP0/s64/photo.jpg","userId":"02869672473237543558"}}},"cell_type":"code","source":["!cd Drive/IR2_project_drive_new/ir2_chatbot && python3 train.py --exp_id_prefix \"b64_h128_em100_orc_9_False\" --n_epochs 25 --batch_size 64 --hidden_dim 128 --emb_dim 100 --merge_type oracle --min_occ 9 --use_bilin False"],"execution_count":2,"outputs":[{"output_type":"stream","text":["v3\n","Bilinear: False, Merge type: oracle, epochs: 25, batch size: 64, hidden dim: 128, embedding dim: 100, min occurences: 9.\n","device cuda:0\n","Getting glove vocab\n","==== Getting the datasets ====\n","\n","Processing file data/experiment_data/bidaf/oracle_short/train-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 230.37 seconds\n","\n","Adding words to the word2id\n","Start getting the words that occur more than 9 times\n","Size of the training dataset: 39862 words\n","Size of GLoVE: 400000 words\n","Without a threshold, the number of words in the intersection is: 34931\n","-- Finished getting the 20031 words that occur more than 9 times\n","It took 0.15 seconds\n","\n","Getting the training set\n","\n","Finished adding words to the word2id\n","It took 14.96 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/train-v1.1.json\n","\n","Processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 31.76 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/dev-v1.1.json\n","\n","Processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","Reading the file\n","-- Finished reading the file\n","It took 31.01 seconds\n","\n","-- Finished processing file data/experiment_data/bidaf/oracle_short/test-v1.1.json\n","\n","==== Finished getting the datasets ====\n","\n","Constructing embeddings matrix\n","checkpoints []\n","Training: Epoch 001/025 Example 34496/34496 (07:15/00:00) | Bilinear loss: 0.0000, Decoder loss: 5.4538\n","Evaluating: Epoch 001/025 Example 04416/04416 (04:03/00:03) | Bilinear loss: 0.0000, Decoder loss: 4.8334\n","Training: Epoch 002/025 Example 34496/34496 (07:20/00:00) | Bilinear loss: 0.0000, Decoder loss: 4.4677\n","Evaluating: Epoch 002/025 Example 04416/04416 (04:24/00:03) | Bilinear loss: 0.0000, Decoder loss: 4.5627\n","Training: Epoch 003/025 Example 34496/34496 (07:27/00:00) | Bilinear loss: 0.0000, Decoder loss: 4.0430\n","Evaluating: Epoch 003/025 Example 04416/04416 (03:44/00:03) | Bilinear loss: 0.0000, Decoder loss: 4.4711\n","Training: Epoch 004/025 Example 34496/34496 (06:58/00:00) | Bilinear loss: 0.0000, Decoder loss: 3.7182\n","Evaluating: Epoch 004/025 Example 04416/04416 (04:17/00:03) | Bilinear loss: 0.0000, Decoder loss: 4.4484\n","Training: Epoch 005/025 Example 34496/34496 (06:29/00:00) | Bilinear loss: 0.0000, Decoder loss: 3.4516\n","Evaluating: Epoch 005/025 Example 04416/04416 (04:46/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.4574\n","Training: Epoch 006/025 Example 34496/34496 (06:32/00:00) | Bilinear loss: 0.0000, Decoder loss: 3.2266\n","Evaluating: Epoch 006/025 Example 04416/04416 (04:54/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.4807\n","Training: Epoch 007/025 Example 34496/34496 (06:28/00:00) | Bilinear loss: 0.0000, Decoder loss: 3.0375\n","Evaluating: Epoch 007/025 Example 04416/04416 (04:49/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.5242\n","Training: Epoch 008/025 Example 34496/34496 (06:36/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.8751\n","Evaluating: Epoch 008/025 Example 04416/04416 (04:30/00:03) | Bilinear loss: 0.0000, Decoder loss: 4.5673\n","Training: Epoch 009/025 Example 34496/34496 (06:25/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.7342\n","Evaluating: Epoch 009/025 Example 04416/04416 (04:39/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.6210\n","Training: Epoch 010/025 Example 34496/34496 (05:54/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.6139\n","Evaluating: Epoch 010/025 Example 04416/04416 (04:39/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.6735\n","Training: Epoch 011/025 Example 34496/34496 (05:34/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.5091\n","Evaluating: Epoch 011/025 Example 04416/04416 (05:51/00:05) | Bilinear loss: 0.0000, Decoder loss: 4.7239\n","Training: Epoch 012/025 Example 34496/34496 (05:47/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.4177\n","Evaluating: Epoch 012/025 Example 04416/04416 (05:12/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.7791\n","Training: Epoch 013/025 Example 34496/34496 (05:47/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.3348\n","Evaluating: Epoch 013/025 Example 04416/04416 (05:15/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.8325\n","Training: Epoch 014/025 Example 34496/34496 (05:42/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.2628\n","Evaluating: Epoch 014/025 Example 04416/04416 (05:10/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.8907\n","Training: Epoch 015/025 Example 34496/34496 (05:42/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.1974\n","Evaluating: Epoch 015/025 Example 04416/04416 (05:33/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.9394\n","Training: Epoch 016/025 Example 34496/34496 (05:44/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.1399\n","Evaluating: Epoch 016/025 Example 04416/04416 (05:00/00:04) | Bilinear loss: 0.0000, Decoder loss: 4.9882\n","Training: Epoch 017/025 Example 34496/34496 (05:36/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.0871\n","Evaluating: Epoch 017/025 Example 04416/04416 (05:27/00:04) | Bilinear loss: 0.0000, Decoder loss: 5.0486\n","Training: Epoch 018/025 Example 34496/34496 (05:27/00:00) | Bilinear loss: 0.0000, Decoder loss: 2.0400\n","Evaluating: Epoch 018/025 Example 04416/04416 (05:26/00:04) | Bilinear loss: 0.0000, Decoder loss: 5.1080\n","Training: Epoch 019/025 Example 34496/34496 (05:34/00:00) | Bilinear loss: 0.0000, Decoder loss: 1.9982\n","Evaluating: Epoch 019/025 Example 04416/04416 (05:14/00:04) | Bilinear loss: 0.0000, Decoder loss: 5.1482\n","Training: Epoch 020/025 Example 34496/34496 (05:43/00:00) | Bilinear loss: 0.0000, Decoder loss: 1.9599\n","Evaluating: Epoch 020/025 Example 04416/04416 (05:06/00:04) | Bilinear loss: 0.0000, Decoder loss: 5.1926\n","Training: Epoch 021/025 Example 34496/34496 (05:59/00:00) | Bilinear loss: 0.0000, Decoder loss: 1.9242\n","Evaluating: Epoch 021/025 Example 04416/04416 (04:28/00:03) | Bilinear loss: 0.0000, Decoder loss: 5.2422\n","Training: Epoch 022/025 Example 34496/34496 (06:11/00:00) | Bilinear loss: 0.0000, Decoder loss: 1.8927\n","Evaluating: Epoch 022/025 Example 04416/04416 (04:11/00:03) | Bilinear loss: 0.0000, Decoder loss: 5.2986\n","Training: Epoch 023/025 Example 34496/34496 (06:49/00:00) | Bilinear loss: 0.0000, Decoder loss: 1.8638\n","Evaluating: Epoch 023/025 Example 04416/04416 (05:07/00:04) | Bilinear loss: 0.0000, Decoder loss: 5.3364\n","Training: Epoch 024/025 Example 34496/34496 (06:39/00:00) | Bilinear loss: 0.0000, Decoder loss: 1.8349\n","Evaluating: Epoch 024/025 Example 04416/04416 (03:03/00:02) | Bilinear loss: 0.0000, Decoder loss: 5.3846\n","Training: Epoch 025/025 Example 34496/34496 (03:40/00:00) | Bilinear loss: 0.0000, Decoder loss: 1.8123\n","Evaluating: Epoch 025/025 Example 04416/04416 (02:27/00:02) | Bilinear loss: 0.0000, Decoder loss: 5.4295\n"],"name":"stdout"}]}]}